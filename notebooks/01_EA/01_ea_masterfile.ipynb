{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82aece48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd992dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable 'PROJECT_ROOT' is already set and will be overwritten by loading .env file. Proceeding...\n",
      "Environment variable 'RAW_DATA_DIR' is already set and will be overwritten by loading .env file. Proceeding...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- IGNORE ---\n",
    "# Environment variables\n",
    "class EnvVarNames:\n",
    "    PROJECT_ROOT = \"PROJECT_ROOT\"\n",
    "    RAW_DATA_DIR = \"RAW_DATA_DIR\"\n",
    "    TEMP_DIR = \"TEMP_DIR\"\n",
    "\n",
    "# check whether environment variables are already set. If so, notify user that they will be overwritten in this process\n",
    "for var_name in [EnvVarNames.PROJECT_ROOT, EnvVarNames.RAW_DATA_DIR]:\n",
    "    if os.getenv(var_name) is not None:\n",
    "        response = print(f\"Environment variable '{var_name}' is already set and will be overwritten by loading .env file. Proceeding...\")\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b7bacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup paths \n",
    "PROJECT_ROOT_ENV_VALUE = os.getenv(EnvVarNames.PROJECT_ROOT)\n",
    "assert PROJECT_ROOT_ENV_VALUE is not None, \"PROJECT_ROOT environment variable is not set.\"\n",
    "PROJECT_ROOT = Path(PROJECT_ROOT_ENV_VALUE)\n",
    "RAW_DATA_DIR_ENV_VALUE = os.getenv(EnvVarNames.RAW_DATA_DIR)\n",
    "assert RAW_DATA_DIR_ENV_VALUE is not None, \"RAW_DATA_DIR environment variable is not set.\"\n",
    "RAW_DATA_DIR = Path(RAW_DATA_DIR_ENV_VALUE)\n",
    "filename = \"Heat Stress Masterfile May 2024.xlsx\"\n",
    "file_path = Path(RAW_DATA_DIR / filename)\n",
    "\n",
    "temp_dir = os.getenv(EnvVarNames.TEMP_DIR)\n",
    "assert temp_dir is not None, \"TEMP_DIR environment variable is not set.\"\n",
    "TEMP_DIR = Path(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb32e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def print_grid_of_values(values:list, items_per_row=3, align_columns=True):\n",
    "    \"\"\"display a list as a grid in the console\"\"\"\n",
    "    if len(values) == 0:\n",
    "        print(\"<no values>\")\n",
    "        return\n",
    "    if align_columns:\n",
    "        max_length = max([len(str(v)) for v in values])\n",
    "        values = [str(v).ljust(max_length) for v in values]\n",
    "    \n",
    "    n = len(values)\n",
    "    i = 0\n",
    "    while(i<n):\n",
    "        j = i + items_per_row\n",
    "        [print(x, end=\" | \") for x in values[i:j]]\n",
    "        print()\n",
    "        i =j\n",
    "\n",
    "def show_unique_values_for_columns(df:pd.DataFrame, columns:list, max_unique_values_to_display=10):\n",
    "    for col in columns:\n",
    "        unique_values = df[col].unique()\n",
    "        n_unique_values = len(unique_values)\n",
    "        print(f\"Column: {col} | Unique values: {n_unique_values}\")\n",
    "        if n_unique_values <= max_unique_values_to_display:\n",
    "            print_grid_of_values(unique_values, items_per_row=5)\n",
    "        else:\n",
    "            print(\"Unique values exceed max display limit.\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "def explore_columns_unique_with_n_unique_values_or_less(df:pd.DataFrame, n:int):\n",
    "    columns_to_explore = [col for col in df.columns if df[col].nunique() <= n]\n",
    "    print_grid_of_values(columns_to_explore, items_per_row=3)\n",
    "    show_unique_values_for_columns(df, columns_to_explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d88282",
   "metadata": {},
   "source": [
    "## Initial quick look at EA Masterfile\n",
    "- How many columns?\n",
    "- How many rows?\n",
    "- How many unique values for key columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30bf7d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (1641, 118)\n",
      "118 columns\n",
      "1641 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(str(file_path), sheet_name=\"RF Ewe.ram data\")\n",
    "\n",
    "print(f\"Dataframe shape: {df.shape}\")\n",
    "print(f\"{df.shape[1]} columns\\n{df.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ff50e",
   "metadata": {},
   "source": [
    "**Filtering rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8677519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the weird row with mostly blanks (sex == 'M' and EID == '940 110012305918')\n",
    "df = df[~((df['sex'] == 'M') & (df['EID'] == '940 110012305918'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de79bb9",
   "metadata": {},
   "source": [
    "At this stage, we're not intererested in males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f80614ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'sex' is 'm' (case insensitive), then drop the row\n",
    "df_filtered = df[~df['sex'].str.lower().eq('m')].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa49024",
   "metadata": {},
   "source": [
    "**Dropping Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e67f919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 25 columns with a single unique value.\n",
      "State                        | Site                         | Farm                         | \n",
      "Breed                        | sex                          | Paddock for 2023 (rams only) | \n",
      "Sensor serial 3 2023         | sensor serial 3 off 2023     | BLOOD TAKEN 2023             | \n",
      "2024 treatment (males)       | Sensor serial 1 2024         | Sensor serial 2 2024         | \n",
      "Sensor serial 3 2024         | GPS # 2024                   | LWC_during_joining_2024      | \n",
      "Sensor serial 1 off 2024     | Sensor serial 2 off 2024     | sensor serial 3 off 2024     | \n",
      "CS_lambing_2024              | WT_lambing_2024              | paddock_lambing_2024         | \n",
      "CS_marking 2024              | WT_marking _2024             | wet_dry_marking_2024         | \n",
      "Comments                     | \n"
     ]
    }
   ],
   "source": [
    "# Drop columns that have only a single unique value (including null)\n",
    "single_value_columns = [col for col in df_filtered.columns if df_filtered[col].nunique(dropna=False) <= 1]\n",
    "df_filtered.drop(columns=single_value_columns, inplace=True)\n",
    "print(f\"Dropped {len(single_value_columns)} columns with a single unique value.\")\n",
    "print_grid_of_values(single_value_columns, items_per_row=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79b32e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EID: 1596 unique values\n",
      "\n",
      "EID VID: 689 unique values\n",
      "\n",
      "VID: 1094 unique values\n",
      "\n",
      "new RE tag 2023: 22 unique values\n",
      "\n",
      "treatment: 6 unique values\n",
      "\n",
      "Drop: 6 unique values\n",
      "\n",
      "Paddock: 4 unique values\n",
      "\n",
      "Weight for allocation 2022: 206 unique values\n",
      "\n",
      "Paddock for 2022 (rams only): 1 unique values\n",
      "\n",
      "date start of joining 2022: 2 unique values\n",
      "\n",
      "WT start of joining 2022: 87 unique values\n",
      "\n",
      "CS start of joining 2022: 14 unique values\n",
      "\n",
      "Collar VEID 2022: 748 unique values\n",
      "\n",
      "Sensor serial 1 2022: 730 unique values\n",
      "\n",
      "Sensor serial 2 2022: 725 unique values\n",
      "\n",
      "Sensor serial 3 2022: 1 unique values\n",
      "\n",
      "GPS # 2022: 743 unique values\n",
      "\n",
      "Date temp logger insterted 2022: 6 unique values\n",
      "\n",
      "Temp logger # 2022: 749 unique values\n",
      "\n",
      "Date end of joining 2022: 3 unique values\n",
      "\n",
      "WT end of joining 2022: 76 unique values\n",
      "\n",
      "CS at end of joining 2022: 22 unique values\n",
      "\n",
      "LWC_during_joining_2022: 33 unique values\n",
      "\n",
      "Collar EID 2022: 748 unique values\n",
      "\n",
      "Sensor serial 1 off 2022: 736 unique values\n",
      "\n",
      "Sensor serial 2 off 2022: 729 unique values\n",
      "\n",
      "sensor serial 3 off 2022: 2 unique values\n",
      "\n",
      "comment: 17 unique values\n",
      "\n",
      "date of preg scanning 2022: 4 unique values\n",
      "\n",
      "WT at preg scanning 2022: 76 unique values\n",
      "\n",
      "CS at preg scanning 2022: 15 unique values\n",
      "\n",
      "BLOOD TAKEN 2022: 746 unique values\n",
      "\n",
      "Preg scan 2022: 4 unique values\n",
      "\n",
      "wet/dry 2022: 3 unique values\n",
      "\n",
      "comments 2022: 8 unique values\n",
      "\n",
      "Weaning date 2022: 1 unique values\n",
      "\n",
      "Weaning weight of ewe 2022: 96 unique values\n",
      "\n",
      "Weight Jan 2023: 73 unique values\n",
      "\n",
      "Weight for allocation 2023: 48 unique values\n",
      "\n",
      "date start of joining 2023: 1 unique values\n",
      "\n",
      "WT start of joining 2023: 71 unique values\n",
      "\n",
      "CS start of joining 2023: 13 unique values\n",
      "\n",
      "Collar VEID 2023: 754 unique values\n",
      "\n",
      "Sensor serial 1 2023: 747 unique values\n",
      "\n",
      "Sensor serial 2 2023: 722 unique values\n",
      "\n",
      "GPS # 2023: 741 unique values\n",
      "\n",
      "Date temp logger insterted 2023: 2 unique values\n",
      "\n",
      "Temp logger # 2023: 754 unique values\n",
      "\n",
      "Date end of joining 2023: 1 unique values\n",
      "\n",
      "WT end of joining 2023: 69 unique values\n",
      "\n",
      "CS at end of joining 2023: 11 unique values\n",
      "\n",
      "LWC_during_joining_2023: 27 unique values\n",
      "\n",
      "Collar EID 2023: 755 unique values\n",
      "\n",
      "Sensor serial 1 off 2023: 750 unique values\n",
      "\n",
      "Sensor serial 2 off 2023: 723 unique values\n",
      "\n",
      "comment.1: 3 unique values\n",
      "\n",
      "date of preg scanning 2023: 1 unique values\n",
      "\n",
      "WT at preg scanning 2023: 66 unique values\n",
      "\n",
      "CS at preg scanning 2023: 11 unique values\n",
      "\n",
      "Preg scan 2023: 3 unique values\n",
      "\n",
      "wet/dry 2023: 2 unique values\n",
      "\n",
      "comments 2023: 10 unique values\n",
      "\n",
      "CS_lambing_2023: 12 unique values\n",
      "\n",
      "WT_lambing_2023: 88 unique values\n",
      "\n",
      "paddock_lambing_2023: 9 unique values\n",
      "\n",
      "CS_marking 2023: 15 unique values\n",
      "\n",
      "WT_marking _2023: 77 unique values\n",
      "\n",
      "wet_dry_marking_2023: 1 unique values\n",
      "\n",
      "Comments 2023: 8 unique values\n",
      "\n",
      "Weaning date 2023: 4 unique values\n",
      "\n",
      "Weaning weight of ewe 2023: 174 unique values\n",
      "\n",
      "EID.1: 1596 unique values\n",
      "\n",
      "Weight for allocation 2024: 77 unique values\n",
      "\n",
      "weight at slaughter 2024: 74 unique values\n",
      "\n",
      "date start of joining 2024: 1 unique values\n",
      "\n",
      "new VID 2024: 7 unique values\n",
      "\n",
      "WT start of joining 2024: 77 unique values\n",
      "\n",
      "CS start of joining 2024: 12 unique values\n",
      "\n",
      "Collar VID 2024 ON: 740 unique values\n",
      "\n",
      "Date temp logger insterted 2024: 1 unique values\n",
      "\n",
      "Temp logger # 2024: 120 unique values\n",
      "\n",
      "Date end of joining 2024: 1 unique values\n",
      "\n",
      "WT end of joining 2024: 76 unique values\n",
      "\n",
      "CS at end of joining 2024: 15 unique values\n",
      "\n",
      "Collar VID 2024 OFF: 741 unique values\n",
      "\n",
      "comments 2024: 12 unique values\n",
      "\n",
      "date of preg scanning 2024: 1 unique values\n",
      "\n",
      "WT at preg scanning 2024: 154 unique values\n",
      "\n",
      "CS at preg scanning 2024: 13 unique values\n",
      "\n",
      "BLOOD TAKEN 2024: 1 unique values\n",
      "\n",
      "Preg scan 2024: 3 unique values\n",
      "\n",
      "Early/Late 2024: 2 unique values\n",
      "\n",
      "comments 2024.1: 2 unique values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df_filtered.columns:\n",
    "    print(f\"{col}: {df_filtered[col].nunique()} unique values\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e3096e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to excel\n",
    "output_file_path = TEMP_DIR / \"ea_masterfile_filtered.xlsx\"\n",
    "df_filtered.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf6d728b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "EID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ea013f89-f9fe-4e3c-89ba-f7470b9ab6a1",
       "rows": [
        [
         "940 110009541187",
         "2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 1
       }
      },
      "text/plain": [
       "EID\n",
       "940 110009541187    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a given col, find values that appear more than n times\n",
    "def find_frequent_values_in_column(df:pd.DataFrame, column_name:str, n:int):\n",
    "    value_counts = df[column_name].value_counts()\n",
    "    frequent_values = value_counts[value_counts > n]\n",
    "    return frequent_values\n",
    "\n",
    "find_frequent_values_in_column(df_filtered, 'EID', 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
